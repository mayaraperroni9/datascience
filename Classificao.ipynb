{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mayaraperroni9/datascience/blob/main/Classificao.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para esse exercício, vamos utilizar o dataset Iris. Ele descreve atributos sobre 3 tipos de flores.\n",
        "O objetivo é classificar qual o tipo de flor de acordo com os atributos disponíveis. Vamos trabalhar apenas com as duas primeiras classes para que\n",
        "o problema de classificação binária."
      ],
      "metadata": {
        "id": "27Q8KCDPV5mU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "iris = load_iris()\n",
        "# Nessa primeira parte, vamos trabalhar apenas com as duas primeiras features e as duas primeiras classes\n",
        "X = iris.data[:100, :4]\n",
        "y = iris.target[:100]\n"
      ],
      "metadata": {
        "id": "RCkrc7OCYsxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### Questão 1.\n",
        "\n",
        "\n",
        "- a) Utilizando o sklearn, defina uma [MLP para classificação binária](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html) com a seguinte configuração:\n",
        "    - função de ativação ReLU;\n",
        "    - duas camadas escondidads com 10 neurônios cada;\n",
        "    - taxa de aprendizado igual a 1e-2;\n",
        "    - utilizando o algoritmo de otimização de gradiente descendente estocástico;\n",
        "    - utilizando 10 iterações máximas (épocas);\n",
        "    - use random_state=1234\n",
        "\n",
        "\n",
        "- b) Treine a MLP definida no conjunto Iris simplificado definido na questão anterior, e calcule a cross-entropy loss binária seguindo a definição a seguir."
      ],
      "metadata": {
        "id": "kBtKuWdgWJ3W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Dividir os dados em conjuntos de treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1234) #precisa ser o mesmo que o do mlp??\n",
        "\n",
        "# Definir o classificador MLP\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(10, 10),\n",
        "                    activation='relu',\n",
        "                    learning_rate_init=0.01,\n",
        "                    solver='sgd',\n",
        "                    max_iter=10,\n",
        "                    random_state=1234)\n",
        "\n",
        "# Treinar o MLP\n",
        "mlp.fit(X_train, y_train)\n",
        "\n",
        "# Prever probabilidades no conjunto de teste\n",
        "y_pred = mlp.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calcular a cross-entropy loss binária\n",
        "loss = log_loss(y_test, y_pred)\n",
        "\n",
        "print(\"Cross-Entropy Loss:\", loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pt6rBMJoW6BQ",
        "outputId": "5011777f-5af1-4270-93c1-a4222fa101d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Entropy Loss: 0.5289903709432386\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### Questão 2.\n",
        "\n",
        "Para avaliar os modelos que serão testados, implemente a função `evaluate_model()`. Essa função recebe um modelo de classificador genérico (`model`) e avalia sua acurácia utilizando **10-fold stratified cross-validation**, retornando a média das acurácias de cada fold. O parâmetro `X` indica os dados e `y` os labels.\n",
        "- Sugestão: há duas formas de implementar a validação cruzada: treinar manualmente os modelos nos [splits gerados](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html) ou utilizar a função [cross_val_score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) do sklearn. Atente-se ao cálculo da acurácia.\n",
        "\n",
        "- Para garantir uma melhor performance dos algoritmos, faça o preprocessamento desses dados através da classe `sklearn.preprocessing.StandardScaler`."
      ],
      "metadata": {
        "id": "7GQGz90SWaqd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "def evaluate_model(model, X, y):\n",
        "    # Criar um pipeline que primeiro normaliza os dados e depois aplica o modelo\n",
        "    pipeline = make_pipeline(StandardScaler(), model)    #ACHO QUE TEM QUE PRÉ-PROCESSAR OS DADOS ANTES DE APLICAR O MODELO, NÃO?\n",
        "\n",
        "    # Configurar a validação cruzada estratificada\n",
        "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=1234)\n",
        "\n",
        "    # Calcular as acurácias de cada fold utilizando o pipeline\n",
        "    accuracies = cross_val_score(pipeline, X, y, cv=cv, scoring='accuracy')\n",
        "\n",
        "    # Retornar a média das acurácias\n",
        "    return accuracies.mean()\n",
        "\n",
        "# Exemplo de como usar a função\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Definir um modelo, por exemplo, MLP\n",
        "model = MLPClassifier(hidden_layer_sizes=(10, 10), max_iter=1000, random_state=1234)\n",
        "\n",
        "# Avaliar o modelo\n",
        "mean_accuracy = evaluate_model(model, X_train, y_train) #melhor usar o train não?\n",
        "print(f\"A média da acurácia com 10-fold stratified cross-validation é: {mean_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkO-fOWVaEY8",
        "outputId": "893b0898-52cf-4ac8-92c5-e908b8e0759a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A média da acurácia com 10-fold stratified cross-validation é: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### Questão 3.\n",
        "\n",
        "Agora para estruturar e organizar melhor nossos testes, vamos utilizar as estruturas de dicionário do Python. Por exemplo, se formos definir dois modelos de Multi-Layer Perceptron, podemos escrever:\n",
        "\n",
        "```\n",
        "experimentos = {\n",
        "    \"MLP camada escondida (5,)\": MLPClassifier(hidden_layer_sizes=(5,),\n",
        "    \"MLP camada escondida (5,5)\": MLPClassifier(hidden_layer_sizes=(5,5)        \n",
        "}\n",
        "```\n",
        "\n",
        "Isso pode ser feito pois o Python trata funções como funções de primeira classe. Isso é, funções podem ser tratadas como variáveis.\n",
        "\n",
        "Portanto, defina um dicionário de experimentos com ao menos 3 modelos de MLP (`sklearn.neural_network.MLPClassifier`). Para isso varie parâmetros como o número de camadas escondidas, função de ativação e número de neurônios.\n",
        "\n",
        "- Dica: Ver documentação em https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n",
        "- Utilize um número de iterações >= 50 para garantir convergência.\n",
        "- Experimente diferentes taxas de aprendizado e número máximo de iterações (épocas) de forma a garantir convergência no treino."
      ],
      "metadata": {
        "id": "0OAqBPC9W7Ul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "experimentos = {\n",
        "    \"MLP 1 camada (10,)\": MLPClassifier(hidden_layer_sizes=(10,), max_iter=1000, tol=1e-4, learning_rate_init=0.001, solver='sgd', momentum=0.9, n_iter_no_change=20, alpha=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-8),\n",
        "    \"MLP 2 camadas (10, 10)\": MLPClassifier(hidden_layer_sizes=(10, 10), max_iter=1000, tol=1e-4, learning_rate_init=0.001, solver='sgd', momentum=0.9, n_iter_no_change=20, alpha=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-8),\n",
        "    \"MLP 3 camadas (10, 10, 10)\": MLPClassifier(hidden_layer_sizes=(10, 10, 10), max_iter=1000, tol=1e-4, learning_rate_init=0.001, solver='sgd', momentum=0.9, n_iter_no_change=20, alpha=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "id": "-bEKtms_bMN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### Questão 4.\n",
        "\n",
        "- a) Para cada modelo instanciado na Questão 3, utilize a função criada na questão 2 para calcular sua acurácia. Exiba o nome do modelo e sua acurácia.\n",
        "- b) Determine qual o melhor classificador dentre os especificados e justifique sua escolha."
      ],
      "metadata": {
        "id": "WF4OInsQXaGJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Avaliar cada modelo\n",
        "for nome, modelo in experimentos.items():\n",
        "    accuracy = evaluate_model(modelo, X, y)\n",
        "    print(f\"{nome}: Acurácia = {accuracy}\")\n",
        "\n",
        "# Identificar o melhor modelo (exemplo de comparação simples)\n",
        "best_model = max(experimentos, key=lambda x: evaluate_model(experimentos[x], X, y))\n",
        "print(f\"Melhor modelo: {best_model}\")\n"
      ],
      "metadata": {
        "id": "uXJF7LngVkjC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9df53429-97be-438b-fece-d03132e47a89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP 1 camada (10,): Acurácia = 1.0\n",
            "MLP 2 camadas (10, 10): Acurácia = 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP 3 camadas (10, 10, 10): Acurácia = 1.0\n",
            "Melhor modelo: MLP 1 camada (10,)\n"
          ]
        }
      ]
    }
  ]
}